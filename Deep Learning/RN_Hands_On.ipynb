{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\"> Machine Learning Hands-On </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 class=\"title\"> Links úteis: </h3>\n",
    "<br>\n",
    "<ol>\n",
    "  <li class=\"item\"><a href = \"http://scikit-learn.org/stable/\"> Sklearn</a>: principal biblioteca de aprendizado de máquina para python.</li>\n",
    "  <li class=\"item\"><a href = \"http://pandas.pydata.org/pandas-docs/stable/\"> Pandas</a>: (quase) tudo o que você precisa para trabalhar rapidamente com tabelas</li>\n",
    "  <li class=\"item\"><a href = \"https://docs.scipy.org/doc/numpy/reference/index.html\"> Numpy</a>: funções matemáticas estão aqui</li>\n",
    "  <li class=\"item\"><a href = \"https://matplotlib.org/contents.html\"> Matplotlib</a>: te ajuda a plotar!</li>\n",
    "  <li class=\"item\"><a href = \"https://seaborn.pydata.org/api.html\"> Seaborn</a>: Deixa a matplotlib bonita (contém plots mais bem estruturados)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid', {\"axes.grid\" : False})\n",
    "sns.set_context('notebook')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center; margin:40px\"> Redes Neurais </h2>\n",
    "\n",
    "\n",
    "O algoritmo de <b>Redes Neurais Artificiais</b> trabalha com abstrações inspiradas em neurônios biológicos. Cada neurônio artificial:\n",
    "<ul>\n",
    "    <li>Recebe <b>diversas entradas</b>, onde cada conexão $x_i$ está associada à um peso $w_i$</li>\n",
    "    <li>Produz <b>somente uma saída</b>, dada pelo output de uma <b>função de ativação</b></li>\n",
    "    <li>O conhecimento fica armazenado nos pesos $w_i$</li>\n",
    "</ul>\n",
    "\n",
    "<br/>\n",
    "<h3> Arquitetura: </h3>\n",
    "Uma rede neural é dividida em 3 tipos de camada:\n",
    "<ul>\n",
    "    <li>Camadas de <b>input</b></li>\n",
    "    <li>Camadas <b>intermediárias</b> ou ocultas</li>\n",
    "    <li>Uma única camada de <b>output</b></li>\n",
    "</ul>\n",
    "\n",
    "<br/>\n",
    "<h3> Predição (Forward Step): </h3>\n",
    "Os dados de entrada \"fluem\" pela arquitetura da rede, sendo multiplicados em cada camada pelos respectivos pesos.\n",
    "\n",
    "<ul>\n",
    "    <li>$H_1 = f_1(W_1^TX)$</li>\n",
    "    <li>$H_2 = f_2(W_2^TH_1)$</li>\n",
    "    <li>$...$</li>\n",
    "    <li>$Output = f_{output}(W_{output}^TH_n)$</li>\n",
    "</ul>\n",
    "\n",
    "<br/>\n",
    "<h3> Aprendizado (Back Propagation): </h3>\n",
    "Após uma predição incorreta, os erros \"fluem de volta\" começando pela camada de output, e corrigindo os pesos a cada passo de modo que eles se adaptem melhor aos dados.\n",
    "\n",
    "<ul>\n",
    "    <li>$w_{ij} := w_{ij} - \\alpha \\, \\frac{\\partial J}{\\partial w_{ij}}$</li>\n",
    "</ul>\n",
    "\n",
    "<br/>\n",
    "<h3> <font color=\"red\">Atenção:</font> Os dados devem ser normalizados antes do treinamento, ou podemos correr o risco de estourar ou zerar os gradientes, fazendo com que a rede não treine!</h3>\n",
    "\n",
    "<br/>\n",
    "<h3> Arquiteturas Populares (Deep Learning): </h3>\n",
    "<ul>\n",
    "    <li><b>Redes Densas (MLPs):</b> Mais usada com dados estruturados</li>\n",
    "    <li><b>Redes Convolucionais (CNNs):</b> Tratamento de imagens e dados com características espaciais</li>\n",
    "    <li><b>Redes Recorrentes (RNNs):</b> Tratamento de sequências (ex: texto)</li>\n",
    "    <li><b>Redes Generativas Adversárias (GANs):</b> Geração de dados artificiais e aprendizado semi-supervisionado</li>\n",
    "</ul>\n",
    "\n",
    "<br/>\n",
    "<h3> Hiperparâmetros </h3>\n",
    "Redes neurais geralmente são mais difíceis de treinar pois existem muitos parâmetros que podem ser tunados, e geralmente é inviável testar uma grande quantidade de parâmetros pois o treinamento da rede é muito custoso.\n",
    "\n",
    "<ul>\n",
    "    <li>Taxa de aprendizado ($\\alpha$)</li>\n",
    "    <li>Número de camadas ocultas</li>\n",
    "    <li>Tamanho de cada camada oculta</li>\n",
    "    <li>(CNNs) Tamanho do Kernel</li>\n",
    "    <li>(CNNs) Tamanho dos strides</li>\n",
    "    <li>...</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scikit-Learn </h3>\n",
    "Agora, vamos rodar os códigos abaixo que usam uma implementação do algoritmo disponível no pacote <i>sklearn</i> (Scikit-Learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(activation = 'relu',\n",
    "                    hidden_layer_sizes = (40, 20, 10),\n",
    "                    max_iter = 5000)\n",
    "baseDados = pd.read_csv('data/base_svm.csv')\n",
    "X = baseDados.loc[:, baseDados.columns != 'Y']\n",
    "Y = baseDados.Y\n",
    "MLP.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = baseDados.X1.min() - .1, baseDados.X1.max() + .1\n",
    "y_min, y_max = baseDados.X2.min() - .1, baseDados.X2.max() + .1\n",
    "h = .01\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = MLP.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap = plt.cm.Accent)\n",
    "\n",
    "pred = MLP.predict(X)\n",
    "plt.scatter(baseDados.X1[Y == 0], baseDados.X2[Y == 0], c = 'darkgreen', marker = '^')\n",
    "plt.scatter(baseDados.X1[Y == 1], baseDados.X2[Y == 1], c = 'black', marker = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
